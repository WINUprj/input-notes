{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e654ccb8-caff-4df2-ab5c-2ea63fa02f8a",
   "metadata": {},
   "source": [
    "# KL Divergence\n",
    "\n",
    "**References**:\n",
    "1. [Revisiting natural gradient for deep networks](https://openreview.net/forum?id=vz8AumxkAfz5U)\n",
    "2. [New Insights and Perspectives on the Natural Gradient\n",
    "Method](https://jmlr.org/papers/volume21/17-678/17-678.pdf)\n",
    "\n",
    "\n",
    "#### Description\n",
    "In high level, KL divergence is the measure of the similarities between two distinct probability distributions that are defined over the identical domain.\n",
    "It frequently appears when one wants to do something with the \"distance\" between two distributions.\n",
    "For instance, the constraints in optimization problems ([Oh, et al., 2020](https://arxiv.org/abs/2007.15308)).\n",
    "Here, I will describe some interesting and useful properties of KL divergence.\n",
    "\n",
    "<!-- ---\n",
    "#### Hessian of KL divergence is equal to Fisher Information Matrix (FIM)\n",
    "We follow the derivation from Reference 1.  -->\n",
    "\n",
    "--- \n",
    "#### KL divergence of exponential family is equivalent to the Bregman divergence of natural parameter\n",
    "The statement can be formalized as: $\\mathbb{D}_{KL} (q_1(\\theta)||q_2(\\theta)) = \\mathbb{D}_{A} (\\lambda_2||\\lambda_1)$.\n",
    "This property is often useful since Bregman divergence is tightly connected the other concepts, such as mirror descent, duality, etc.\n",
    "\n",
    "*Proof*:\n",
    "\\begin{align*}\n",
    "\\mathbb{D}_{KL}(q_1 || q_2) &= \\int_\\Theta q_1(\\theta) \\log \\frac{q_1(\\theta)}{q_2(\\theta)} d\\theta \\\\\n",
    "    &= \\int_\\Theta q_1(\\theta) log\\left[ \\frac{\\exp (\\langle \\lambda_1, T(\\theta) \\rangle - A(\\lambda_1)) h(\\theta)}{ \\exp( \\langle \\lambda_2, T(\\theta) \\rangle - A(\\lambda_2) ) h(\\theta) } \\right] d\\theta \\\\\n",
    "    &= \\int_\\Theta q_1(\\theta) (\\langle \\lambda_1, T(\\theta) \\rangle - A(\\lambda_1) - \\langle \\lambda_2, T(\\theta) \\rangle + A(\\lambda_2)) d\\lambda \\\\\n",
    "    &= A(\\lambda_1) - A(\\lambda_2) - \\int_\\Theta q_1(\\theta) \\langle \\lambda_2 - \\lambda_1, T(\\theta) \\rangle d\\theta \\\\\n",
    "    &= A(\\lambda_1) - A(\\lambda_2) - \\langle \\lambda_2 - \\lambda_1, \\nabla_\\lambda A(\\lambda_1) \\rangle  \\textnormal{\\:\\:\\:(From differential identity)} \\\\\n",
    "    &= \\mathbb{D}_A(\\lambda_2 || \\lambda_1)\n",
    "\\end{align*}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
